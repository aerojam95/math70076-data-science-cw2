{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "# Modules\n",
    "#=============================================================================\n",
    "\n",
    "# Standard modules\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets import FashionMNIST   \n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Custom modules\n",
    "from logger import logProgress\n",
    "from data_loader import loadImages, loadLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "# Variables\n",
    "#=============================================================================\n",
    "\n",
    "# Path to the JSON metadata file\n",
    "metadataFilePath = \"configurations.json\"\n",
    "\n",
    "# Pixel normalisation value\n",
    "pixels = 255.\n",
    "\n",
    "# Seed for repeatable random initialisations\n",
    "seed = np.random.seed(123456789)\n",
    "\n",
    "# Set loss function for DL methods\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 May 2024 21:22:45: Starting programme...\n",
      "01 May 2024 21:22:45: Importing metadata...\n",
      "01 May 2024 21:22:45: Imported metadata\n",
      "01 May 2024 21:22:45: Updating metadata file...\n",
      "01 May 2024 21:22:45: Updated metadata file\n",
      "01 May 2024 21:22:45: Loading data...\n",
      "01 May 2024 21:22:46: Loaded data\n",
      "01 May 2024 21:22:46: Pre-processing image data...\n",
      "01 May 2024 21:22:47: Pre-processed image data\n"
     ]
    }
   ],
   "source": [
    " # Logging\n",
    "logProgress(\"Starting programme...\")\n",
    "\n",
    "#==========================================================================\n",
    "# Data loading\n",
    "#==========================================================================\n",
    "\n",
    "# Reading the JSON configuration file\n",
    "logProgress(\"Importing metadata...\")\n",
    "with open(metadataFilePath, \"r\") as metadata_file:\n",
    "    jsonData = json.load(metadata_file)\n",
    "logProgress(\"Imported metadata\")\n",
    "\n",
    "# Setting metadata variables\n",
    "loggingName     = jsonData[\"loggingName\"]\n",
    "runNumber       = jsonData[\"runNumber\"]\n",
    "dataPath        = jsonData[\"dataPath\"]\n",
    "outputFigPath   = jsonData[\"outputFigPath\"]\n",
    "outputValPath   = jsonData[\"outputValPath\"]\n",
    "outputModelPath = jsonData[\"outputModelPath\"]\n",
    "\n",
    "# Update metadata file for next run\n",
    "logProgress(\"Updating metadata file...\")\n",
    "jsonData[\"runNumber\"] = str(int(runNumber) + 1)\n",
    "with open(metadataFilePath, 'w') as metadata_file:\n",
    "    json.dump(jsonData, metadata_file, indent=4)\n",
    "logProgress(\"Updated metadata file\")\n",
    "\n",
    "# Paths to the downloaded data files\n",
    "trainImagesPath = os.path.join(dataPath, \"train-images-idx3-ubyte.gz\")\n",
    "trainLabelsPath = os.path.join(dataPath, \"train-labels-idx1-ubyte.gz\")\n",
    "testImagesPath  = os.path.join(dataPath, \"t10k-images-idx3-ubyte.gz\")\n",
    "testLabelsPath  = os.path.join(dataPath, \"t10k-labels-idx1-ubyte.gz\")\n",
    "\n",
    "# Load the datasets\n",
    "logProgress(\"Loading data...\")\n",
    "trainImages = loadImages(trainImagesPath)\n",
    "trainLabels = loadLabels(trainLabelsPath)\n",
    "testImages  = loadImages(testImagesPath)\n",
    "testLabels  = loadLabels(testLabelsPath)\n",
    "logProgress(\"Loaded data\")\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# Data pre-processing\n",
    "#==========================================================================\n",
    "\n",
    "# pre-process images\n",
    "logProgress(\"Pre-processing image data...\")\n",
    "trainImages = trainImages.reshape(trainImages.shape[0], -1) / pixels\n",
    "testImages = testImages.reshape(testImages.shape[0], -1) / pixels\n",
    "logProgress(\"Pre-processed image data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Apr 2024 20:06:17: Running Naive-Bayes...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m logProgress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Naive-Bayes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m GNB \u001b[38;5;241m=\u001b[39m GaussianNaiveBayes()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mGNB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainImages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestImages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestLabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m logProgress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive-Bayes completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m GNB\u001b[38;5;241m.\u001b[39msaveModel(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputModelPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mnaive_bayes_model_parameters_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunNumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/d/Google Drive/Documents/Education/University/Imperial College London/Statistics & Data Science Msc 2023-2024/Term 2/math70076-data-science-cw2/src/gnb.py:55\u001b[0m, in \u001b[0;36mGaussianNaiveBayes.run\u001b[0;34m(self, trainImages, trainLabels, valImages, valLabels)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses:\n\u001b[1;32m     54\u001b[0m     sep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainLabels \u001b[38;5;241m==\u001b[39m category] \n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainLabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43msep\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainLabels[sep]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainLabels))\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainImages[sep], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive-Bayes\n",
    "\n",
    "from gnb import GaussianNaiveBayes\n",
    "\n",
    "logProgress(\"Running Naive-Bayes...\")\n",
    "GNB = GaussianNaiveBayes()\n",
    "GNB.run(trainImages, trainLabels, testImages, testLabels)\n",
    "logProgress(\"Naive-Bayes completed\")\n",
    "\n",
    "GNB.saveModel(f\"{outputModelPath}naive_bayes_model_parameters_{runNumber}.txt\")\n",
    "logProgress(\"Naive-Bayes model saved\")\n",
    "\n",
    "GNB.saveValidation(f\"{outputValPath}naive_bayes_validation_results_{runNumber}.txt\")\n",
    "logProgress(\"Naive-Bayes validation accuracy saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 May 2024 02:23:34: Training k-Nearest neighbours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 24/60000 [00:07<5:11:45,  3.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m logProgress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining k-Nearest neighbours...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m kNN \u001b[38;5;241m=\u001b[39m kNearestNeighbours()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mkNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutputFigPath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrunNumber\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainImages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m logProgress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-Nearest neighbours training completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m logProgress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidating k-Nearest neighbours...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/d/Google Drive/Documents/Education/University/Imperial College London/Statistics & Data Science Msc 2023-2024/Term 2/math70076-data-science-cw2/src/knn.py:66\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, CurvePath, trainImages, trainLabel, kmin, kmax)\u001b[0m\n\u001b[1;32m     64\u001b[0m tr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(trainImages, p, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     65\u001b[0m train_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(trainLabel, p)\n\u001b[0;32m---> 66\u001b[0m diff \u001b[38;5;241m=\u001b[39m tr \u001b[38;5;241m-\u001b[39m te\n\u001b[1;32m     67\u001b[0m dis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mij, ij->i\u001b[39m\u001b[38;5;124m'\u001b[39m, diff, diff)\n\u001b[1;32m     68\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/mnt/d/Google Drive/Documents/Education/University/Imperial College London/Statistics & Data Science Msc 2023-2024/Term 2/mscDataScienceEnv/lib/python3.11/site-packages/numpy/core/einsumfunc.py:1001\u001b[0m, in \u001b[0;36m_einsum_dispatcher\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m     path \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meinsum_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m path\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (path, path_print)\n\u001b[0;32m-> 1001\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_einsum_dispatcher\u001b[39m(\u001b[38;5;241m*\u001b[39moperands, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;66;03m# Arguably we dispatch on more arguments than we really should; see note in\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# _einsum_path_dispatcher for why.\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m operands\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# k-Nearest neighbours\n",
    "\n",
    "from knn import kNearestNeighbours\n",
    "\n",
    "logProgress(\"Training k-Nearest neighbours...\")\n",
    "kNN = kNearestNeighbours()\n",
    "kNN.train(f\"{outputFigPath}{runNumber}\", trainImages, trainLabels, kmin=1, kmax=20)\n",
    "logProgress(\"k-Nearest neighbours training completed\")\n",
    "\n",
    "logProgress(\"Validating k-Nearest neighbours...\")\n",
    "kNN.predict(f\"{outputFigPath}{runNumber}\", trainImages, trainLabels, testImages, testLabels, k=kNN.k)\n",
    "logProgress(\"k-Nearest neighbours validation completed\")\n",
    "\n",
    "kNN.saveModel(f\"{outputModelPath}{runNumber}_knn_model_parameters_.txt\")\n",
    "logProgress(\"k-Nearest neighbours model saved\")\n",
    "\n",
    "kNN.saveValidation(f\"{outputValPath}{runNumber}_knn_validation_results.txt\")\n",
    "logProgress(\"k-Nearest neighbours validation accuracy saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 May 2024 21:24:08: Training neural network...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'ReLU'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m test_loader   \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(test_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m logProgress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining neural network...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m NN \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(NN\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     21\u001b[0m NN\u001b[38;5;241m.\u001b[39mtrain(train_loader, criterion, optimizer, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputFigPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrunNumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/d/Google Drive/Documents/Education/University/Imperial College London/Statistics & Data Science Msc 2023-2024/Term 2/math70076-data-science-cw2/src/nn.py:66\u001b[0m, in \u001b[0;36mNeuralNetwork.__init__\u001b[0;34m(self, imageDimensions, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2     \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3     \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReLU\u001b[49m()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax    \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictAccuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/d/Google Drive/Documents/Education/University/Imperial College London/Statistics & Data Science Msc 2023-2024/Term 2/mscDataScienceEnv/lib/python3.11/site-packages/torch/__init__.py:1833\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1830\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m   1831\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m-> 1833\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'ReLU'"
     ]
    }
   ],
   "source": [
    "from nn import NeuralNetwork\n",
    "\n",
    "# Transformations applied on each image => first make them a tensor, then normalize them in the range -1 to 1\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_set = FashionMNIST(root=\"./\", train=True, transform=transform, download=True)\n",
    "\n",
    "# Loading the test set\n",
    "test_set = FashionMNIST(root=\"./\",train=False, transform=transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "# Note that for actually training a model, we will use different data loaders\n",
    "# with a lower batch size.\n",
    "train_loader  = data.DataLoader(train_set, batch_size=64, shuffle=True, drop_last=False)\n",
    "test_loader   = data.DataLoader(test_set, batch_size=64, shuffle=False, drop_last=False)\n",
    "\n",
    "logProgress(\"Training neural network...\")\n",
    "NN = NeuralNetwork()\n",
    "optimizer = optim.Adam(NN.parameters(), lr=0.001)\n",
    "NN.train(train_loader, criterion, optimizer, f\"{outputFigPath}{runNumber}_\")\n",
    "logProgress(\"neural network training completed\")\n",
    "\n",
    "logProgress(\"Validating neural network...\")\n",
    "NN.evaluate(test_loader)\n",
    "logProgress(\"Neural network validation completed\")\n",
    "\n",
    "NN.saveModel(f\"{outputModelPath}{runNumber}_nn_model.pth\")\n",
    "logProgress(\"Neural network model saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscDataScienceEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
